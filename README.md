# QuietlyCode IDE

A calm, local, private AI pair-programmer. No cloud. No telemetry. No distractions.

**Offline-First Local AI IDE** powered by [BitNet.cpp](https://github.com/microsoft/BitNet) for local 1-bit LLM inference.

## Features

- âš¡ **Fully Offline** â€” All inference runs locally via BitNet.cpp, zero internet required after setup
- ğŸ§  **AI Chat Panel** â€” Streaming AI responses for code questions, explanations, and generation
- âœï¸ **Monaco Editor** â€” Full-featured code editor with syntax highlighting for 30+ languages
- ğŸ” **Explain Code** â€” Select code â†’ right-click â†’ AI explains it
- â™»ï¸ **Refactor Selection** â€” AI-powered code refactoring with inline diff preview
- ğŸ¨ **Dark & Light Themes** â€” Beautiful custom themes with smooth transitions
- âŒ¨ï¸ **Keyboard-First** â€” Command palette (Ctrl+Shift+P), shortcuts for all actions
- ğŸ“ **File Explorer** â€” Project tree with file open/save support
- âš™ï¸ **Configurable** â€” Model path, context size, temperature, max tokens, threads
- ğŸ“¥ **Model Download** â€” Built-in interface to download BitNet models from Hugging Face

## Prerequisites

1. **Node.js** 18+ and npm
2. **BitNet.cpp** compiled with `llama-server` binary ([build guide](https://github.com/microsoft/BitNet#build-from-source))
3. A **GGUF model** file (download via the built-in setup screen or from [HuggingFace](https://huggingface.co/microsoft/BitNet-b1.58-2B-4T-gguf))

## Quick Start

```bash
# 1. Install dependencies
npm install

# 2. Run in development mode
npm run dev

# 3. On first launch, the Setup Screen will guide you to:
#    - Download a BitNet model
#    - Configure the llama-server binary path
```

## Build for Production

```bash
npm run build
```

## Keyboard Shortcuts

| Shortcut         | Action                |
| ---------------- | --------------------- |
| Ctrl+Shift+P     | Command Palette       |
| Ctrl+S           | Save File             |
| Ctrl+B           | Toggle Sidebar        |
| Ctrl+J           | Toggle AI Panel       |
| Ctrl+,           | Settings              |
| Ctrl+Shift+E     | AI: Explain Selection |
| Ctrl+Shift+R     | AI: Refactor Selection|
| Ctrl+K           | AI: Edit Selection    |

## Architecture

```
src/
â”œâ”€â”€ main/                    # Electron main process
â”‚   â”œâ”€â”€ index.ts             # Window management & IPC handlers
â”‚   â”œâ”€â”€ ai-service.ts        # llama-server subprocess manager
â”‚   â”œâ”€â”€ file-service.ts      # File system operations
â”‚   â””â”€â”€ model-downloader.ts  # HuggingFace model downloader
â”œâ”€â”€ preload/
â”‚   â””â”€â”€ index.ts             # IPC bridge (contextBridge)
â””â”€â”€ renderer/                # React UI
    â”œâ”€â”€ App.tsx              # Root layout & keyboard shortcuts
    â”œâ”€â”€ index.css            # Design system & themes
    â”œâ”€â”€ store/appStore.ts    # State management (Context + useReducer)
    â”œâ”€â”€ prompts/index.ts     # AI prompt templates
    â””â”€â”€ components/
        â”œâ”€â”€ SetupScreen.tsx  # First-run model download
        â”œâ”€â”€ TitleBar.tsx     # Frameless window controls
        â”œâ”€â”€ Sidebar.tsx      # File explorer tree
        â”œâ”€â”€ Editor.tsx       # Monaco Editor wrapper
        â”œâ”€â”€ TabBar.tsx       # Editor tabs
        â”œâ”€â”€ ChatPanel.tsx    # AI chat with streaming
        â”œâ”€â”€ StatusBar.tsx    # Bottom status bar
        â”œâ”€â”€ SettingsPanel.tsx    # Configuration modal
        â”œâ”€â”€ CommandPalette.tsx   # Ctrl+Shift+P commands
        â”œâ”€â”€ DiffPreview.tsx     # Inline diff viewer
        â””â”€â”€ ContextMenu.tsx     # Right-click menu
```

## Design Philosophy

- **Privacy first** â€” All code stays on your machine
- **No telemetry** â€” Zero tracking, zero external calls
- **Minimal & calm** â€” Professional UI without distractions
- **CPU-friendly** â€” Target: 16GB RAM laptops (Min), CPU-only inference


